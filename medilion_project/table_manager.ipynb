{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56258588-4bb6-43c2-8bd3-733d4be190b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 01_table_manager.py\n",
    "from pyspark.sql import SparkSession\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "class InvalidNamespaceError(ValueError):\n",
    "    pass\n",
    "\n",
    "class TableManager:\n",
    "    \"\"\"\n",
    "    Manage Unity Catalog catalog/schema/table objects using Spark SQL.\n",
    "\n",
    "    Usage:\n",
    "        tm = TableManager(spark, catalog=\"demo_catalog\", schema=\"demo_schema\")\n",
    "        tm.create_managed_table(\"demo_table\", \"id INT, name STRING\")\n",
    "        tm.list_tables()\n",
    "    \"\"\"\n",
    "\n",
    "    DOT_ALLOWED = re.compile(r\"^[A-Za-z0-9_]+$\")  # simple allowed-name check\n",
    "\n",
    "    def __init__(self, spark: SparkSession, catalog: str, schema: str):\n",
    "        self.spark = spark\n",
    "        self.catalog = catalog.strip()\n",
    "        self.schema = schema.strip()\n",
    "        self._validate_namespace()\n",
    "        return(self.catalog,self.schema)\n",
    "\n",
    "    def _validate_namespace(self):\n",
    "        # Ensure neither catalog nor schema is empty and they do not contain dots\n",
    "        if not self.catalog or not self.schema:\n",
    "            raise InvalidNamespaceError(\"Catalog and schema must be non-empty.\")\n",
    "        if \".\" in self.catalog or \".\" in self.schema:\n",
    "            raise InvalidNamespaceError(\"Catalog and schema must not contain dots. Use catalog and schema separately.\")\n",
    "        # optional: check allowed characters\n",
    "        if not self.DOT_ALLOWED.match(self.catalog) or not self.DOT_ALLOWED.match(self.schema):\n",
    "            raise InvalidNamespaceError(\"Catalog/schema names contain invalid characters. Use alphanumeric and underscore only.\")\n",
    "\n",
    "    @property\n",
    "    def full_schema(self) -> str:\n",
    "        return f\"{self.catalog}.{self.schema}\"\n",
    "\n",
    "    def use_schema(self):\n",
    "        \"\"\"Switch current session to the catalog and schema.\"\"\"\n",
    "        # Use uppercase SQL keywords to be clear\n",
    "        self.spark.sql(f\"USE CATALOG {self.catalog}\")\n",
    "        self.spark.sql(f\"USE SCHEMA {self.catalog}.{self.schema}\")\n",
    "\n",
    "    def create_managed_table(self, table_name: str, columns_sql: str):\n",
    "        \"\"\"\n",
    "        Create a managed Delta table in Unity Catalog.\n",
    "        table_name: single identifier (no dots)\n",
    "        columns_sql: e.g. \"id INT, name STRING, amount DOUBLE\"\n",
    "        \"\"\"\n",
    "        if \".\" in table_name:\n",
    "            raise InvalidNamespaceError(\"table_name must be a single identifier (no dots).\")\n",
    "        self.use_schema()\n",
    "        create_sql = f\"CREATE TABLE IF NOT EXISTS demo_catalog.demo_schema.{table_name} ({columns_sql}) USING DELTA\"\n",
    "        self.spark.sql(create_sql)\n",
    "\n",
    "    def drop_table(self, table_name: str):\n",
    "        if \".\" in table_name:\n",
    "            raise InvalidNamespaceError(\"table_name must be a single identifier (no dots).\")\n",
    "        self.use_schema()\n",
    "        self.spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "    def list_tables(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return a list of table names in the configured catalog.schema.\n",
    "\n",
    "        Implementation notes:\n",
    "          - Uses SHOW TABLES IN <catalog>.<schema> then extracts tableName column.\n",
    "          - Avoids nested/empty namespace mistakes by using validated full_schema.\n",
    "        \"\"\"\n",
    "        self.use_schema()\n",
    "        df = self.spark.sql(f\"SHOW TABLES IN {self.full_schema}\")\n",
    "        # df has columns: database, tableName, isTemporary\n",
    "        if \"tableName\" in df.columns:\n",
    "            return [row[\"tableName\"] for row in df.collect()]\n",
    "        # fallback: try to extract 'name'/'table' fields\n",
    "        return [row[0] for row in df.collect()]\n",
    "\n",
    "    def describe_table(self, table_name: str):\n",
    "        if \".\" in table_name:\n",
    "            raise InvalidNamespaceError(\"table_name must be a single identifier (no dots).\")\n",
    "        self.use_schema()\n",
    "        return self.spark.sql(f\"DESCRIBE TABLE {table_name}\").collect()\n",
    "\n",
    "    def run_query(self, sql: str):\n",
    "        \"\"\"Run an arbitrary SQL statement in this schema (switches to schema first).\"\"\"\n",
    "        self.use_schema()\n",
    "        return self.spark.sql(sql)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "table_manager",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
